# jemdoc: menu{MENU}{publications.html}, nofooter
== Publications 

For the complete list, please refer to my [https://scholar.google.com/citations?user=AKxBgssAAAAJ Google Scholar Profile].

\* indicates equal contribution

== {{<font color="red">Benchmark</font>}}

The adversarially trained NAS benchmark (*NAS-RobBench-201*) in [https://openreview.net/pdf?id=cdUpf6t6LZ our ICLR24 paper] was released! See \[[https://tt2408.github.io/nasrobbench201hp/ project website]\] for details.


== Preprints

- /Can overfitted deep neural networks in adversarial training generalize? -- An approximation viewpoint/. 
\[[https://arxiv.org/abs/2401.13624 arXiv]\]. \n
Zhongjie Shi, *Fanghui Liu*,  Yuan Cao, Johan A.K. Suykens. \n


== Accepted Papers

- /Generalization of Deep ResNets in the mean-field regime/. 
\[[https://openreview.net/forum?id=tMzPZTvz2H link]\]. \n
Yihang Chen, *Fanghui Liu*, Yiping Lu, Grigorios Chrysos, Volkan Cevher. \n
in the 12th International Conference on Learning Representations (*ICLR*), 2024. {{<font color="red">[Spotlight]</font>}} \n

- /Robust NAS benchmark under adversarial training: assessment, theory, and beyond/. 
\[[https://openreview.net/forum?id=cdUpf6t6LZ link]\], \[[https://tt2408.github.io/nasrobbench201hp/ project website]\]. \n
Yongtao Wu, *Fanghui Liu*, Carl-Johann Simon-Gabriel, Grigorios Chrysos, Volkan Cevher. \n
in the 12th International Conference on Learning Representations (*ICLR*), 2024. \n

- /Efficient local linearity regularization to overcome catastrophic overfitting/. 
\[[https://openreview.net/forum?id=SZzQz8ikwg link]\], \[[https://github.com/LIONS-EPFL/ELLE code]\]. \n
Elias Abad Rocamora, *Fanghui Liu*, Grigorios Chrysos, Pablo M. Olmos, Volkan Cevher. \n
in the 12th International Conference on Learning Representations (*ICLR*), 2024. \n

- /On the convergence of encoder-only shallow Transformers/. 
\[[https://arxiv.org/abs/2311.01575 arxiv]\]. \n
Yongtao Wu, *Fanghui Liu*, Grigorios Chrysos, Volkan Cevher. \n
in the 37th Conference on Neural Information Processing Systems (*NeurIPS*), 2023. \n

- /Initialization matters: Privacy-utility analysis of overparameterized neural networks/. 
\[[https://arxiv.org/abs/2310.20579 arXiv]\]. \n
Jiayuan Ye, Zhenyu Zhu, *Fanghui Liu*, Reza Shokri, Volkan Cevher. \n
in the 37th Conference on Neural Information Processing Systems (*NeurIPS*), 2023. \n

- /What can online reinforcement learning with function approximation benefit from general coverage conditions?/. 
\[[https://arxiv.org/abs/2304.12886 arXiv]\]. \n
*Fanghui Liu*, Luca Viano, Volkan Cevher. \n
in the 40th International Conference on Machine Learning (*ICML*), 2023. \n

- /Benign Overfitting in Deep Neural Networks under Lazy Training/. 
\[[https://arxiv.org/abs/2305.19377 arXiv]\]. \n
Zhenyu Zhu, *Fanghui Liu*,  Grigorios Chrysos, Francesco Locatello, Volkan Cevher. \n
in the 40th International Conference on Machine Learning (*ICML*), 2023. \n

- /On the double descent of random features models trained by SGD/. 
\[[https://arxiv.org/abs/2110.06910 arXiv]\],
\[[files/code_DD_RFF.zip code]\], \[[files/Fanghui_DD.pdf slides]\]. \n
*Fanghui Liu*, Johan A.K. Suykens, Volkan Cevher. \n
in the 36th Conference on Neural Information Processing Systems (*NeurIPS*), 2022. \n
Presented at [https://topml.rice.edu/ Workshop on the Theory of Overparameterized Machine Learning (TOPML) 2022].

- /Understanding deep neural function approximation in reinforcement learning via $\epsilon$-greedy exploration/. 
\[[https://arxiv.org/abs/2209.07376 arXiv]\]. \n
*Fanghui Liu*, Luca Viano, Volkan Cevher. \n
in the 36th Conference on Neural Information Processing Systems (*NeurIPS*), 2022. \n

- /Robustness in deep learning: The good (width), the bad (depth), and the ugly (initialization)/. 
\[[https://arxiv.org/abs/2209.07263 arXiv]\], \[[files/NeurIPS22-robustness.pdf slides]\]. \n
Zhenyu Zhu, *Fanghui Liu*,  Grigorios Chrysos, Volkan Cevher. \n
in the 36th Conference on Neural Information Processing Systems (*NeurIPS*), 2022. \n

- /Generalization properties of NAS under activation and skip connection search/.
\[[https://arxiv.org/abs/2209.07238 arXiv]\]. \n
Zhenyu Zhu, *Fanghui Liu*, Grigorios Chrysos, Volkan Cevher. \n
in the 36th Conference on Neural Information Processing Systems (*NeurIPS*), 2022. \n

- /Extrapolation and spectral bias of neural nets with Hadamard product: a polynomial net study/.
\[[https://arxiv.org/abs/2209.07736 arXiv]\]. \n
Yongtao Wu, Zhenyu Zhu, *Fanghui Liu*, Grigorios Chrysos, Volkan Cevher. \n
in the 36th Conference on Neural Information Processing Systems (*NeurIPS*), 2022. \n

- /Sound and complete verification of polynomial networks/. \[[https://arxiv.org/abs/2209.07235 arXiv]\]. \n
Elias Abad Rocamora, Mehmet Fatih Sahin, *Fanghui Liu*, Grigorios Chrysos, Volkan Cevher. \n
in the 36th Conference on Neural Information Processing Systems (*NeurIPS*), 2022. \n

- /Random features for kernel approximation: A Survey on algorithms, theory, and beyond/.
\[[https://arxiv.org/abs/2004.11154 arXiv]\], \[[files/RFFsurvey_demo.zip code]\]. \n
*Fanghui Liu*, Xiaolin Huang, Yudong Chen, and Johan A.K. Suykens. \n
IEEE Transactions on Pattern Analysis and Machine Intelligence (*TPAMI*), 2021.

- /Generalization properties of hyper-RKHS and its applications/.
\[[https://jmlr.org/papers/v22/19-482.html link]\], \[[files/demo-hyperRKHS.zip code]\]. \n
*Fanghui Liu*\*, Lei Shi\*, Xiaolin Huang, Jie Yang, and Johan A.K. Suykens. \n
Journal of Machine Learning Research (*JMLR*), 2021.

- /Towards a unified quadrature framework for large scale kernel methods/.
\[[https://arxiv.org/abs/2011.01668 arXiv]\], \[[files/Quadrature_demo.zip code]\]. \n
*Fanghui Liu*, Xiaolin Huang, Yudong Chen, and Johan A.K. Suykens.\n
IEEE Transactions on Pattern Analysis and Machine Intelligence (*TPAMI*), 2021.

- /Kernel regression in high dimensions: Refined analysis beyond double descent/.
\[[http://proceedings.mlr.press/v130/liu21b.html link]\], \[[files/demo_KRRhigh.m code]\], \[[files/Fanghui_KRR.pdf slides]\]. \n
*Fanghui Liu*, Zhenyu Liao, and Johan A.K. Suykens.\n 
in the 24th International Conference on Artificial Intelligence and Statistics (*AISTATS*), 2021.

- /Fast learning in reproducing kernel Krein spaces via signed measures/.
\[[http://proceedings.mlr.press/v130/liu21a.html link]\], \[[files/RFF_RKKS_poster.pdf poster]\],
 \[[files/code-RFF_RKKS.zip code]\]. \n
*Fanghui Liu*, Xiaolin Huang, Yingyi Chen, and Johan A.K. Suykens. \n
in the 24th International Conference on Artificial Intelligence and Statistics (*AISTATS*), 2021.

- /Analysis of least squares regularized regression in reproducing kernel Krein spaces/.
\[[https://arxiv.org/abs/2006.01073 arXiv]\]. \n
*Fanghui Liu*\*, Lei Shi\*, Xiaolin Huang, Jie Yang, and Johan A.K. Suykens. \n
*Machine Learning*, 2021.

- /Learning data-adaptive nonparametric kernels/.
\[[https://jmlr.org/papers/v21/19-900.html link]\] \[[files/NesterovAcc.m code]\]. \n
*Fanghui Liu*, Xiaolin Huang, Chen Gong, Jie Yang, and Li Li. \n
Journal of Machine Learning Research (*JMLR*), 2020.

- /Random Fourier features via fast surrogate leverage weighted sampling/.
\[[https://arxiv.org/abs/1911.09158 arXiv]\], \[[files/AAAI20_code.zip code]\].\n 
*Fanghui Liu*, Xiaolin Huang, Yudong Chen, Jie Yang, and Johan A.K. Suykens. \n
in the Thirty-Fourth AAAI Conference on Artificial Intelligence (*AAAI*), 2020.

- /A double-variational Bayesian framework in random Fourier features 
 for indefinite kernels/.
\[[https://lirias.kuleuven.be/retrieve/554716 link]\], \[[files/RFF-DIGMM_code.zip code]\].\n
*Fanghui Liu*, Xiaolin Huang, Lei Shi, Jie Yang, and Johan A.K. Suykens.\n 
IEEE Transactions on Neural Networks and Learning Systems (*TNNLS*), 2019.

- /Indefinite kernel logistic regression with Concave-inexact-convex procedure/.
\[[https://arxiv.org/abs/1707.01826 arXiv]\], \[[files/IKLR_code.zip code]\]. \n
*Fanghui Liu*, Xiaolin Huang, Chen Gong, Jie Yang, and Johan A.K. Suykens. \n
IEEE Transactions on Neural Networks and Learning Systems (*TNNLS*), 2018.

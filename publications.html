<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="icon" href="images/icon.png">
<link rel="stylesheet" href="main.css" type="text/css" />
<link rel="stylesheet" href="font-awesome/css/font-awesome.min.css">
<!--- <title>Publications </title> --->
<title>Fanghui Liu</title>
<!-- MathJax -->
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML' async>
</script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
	  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
<!-- End MathJax -->
</head>
<body>
<div id="main-container">
<div id="header-container">
<div id="header">
<div id="header-icon-text-container">
<div id="header-icon-container" >
<a href="index.html"><img src="images/profile2.png" alt="" style="width: 100%; height: 100%; position: center; padding:0px; margin: 0px;"></a>
</div>
<div id="header-text-container">
<a href="index.html">Fanghui Liu</a>
</div>
</div>
<div id="main">
<button class="openbtn" onclick="openNav()">☰</button>
</div>
</div>
</div>
<div id="layout">
<div id="layout-menu-container">
<div id="layout-menu">
<div class="menu-item"><a href="javascript:void(0)" class="closebtn" onclick="closeNav()">×</a></div>
<div class="menu-item"><a href="index.html">About</a></div>
<div class="menu-category">Research</div>
<div class="menu-item"><a href="publications.html" class="current">Publications</a></div>
<div class="menu-item"><a href="talks.html">Talks</a></div>
<div class="menu-item"><a href="services.html">Services</a></div>
<div class="menu-item"><a href="awards.html">Awards</a></div>
</div> <!-- <div id="layout-menu"> -->
</div> <!-- <div id="layout-menu-container"> -->
<div id="layout-content-container">
<div id="layout-content">
<div id="toptitle">
<h1>Publications </h1>
</div>
<p>For the complete list, please refer to my <a href="https://scholar.google.com/citations?user=AKxBgssAAAAJ" target=&ldquo;blank&rdquo;>Google Scholar Profile</a>.</p>
<p>* indicates equal contribution</p>
<h3>Preprints</h3>
<p>!</p>
<h2>Accepted Papers</h2>
<ul>
<li><p><i>On the double descent of random features models trained by SGD</i>. 
[<a href="https://arxiv.org/abs/2110.06910" target=&ldquo;blank&rdquo;>arXiv</a>],
[<a href="files/code_DD_RFF.zip" target=&ldquo;blank&rdquo;>code</a>] <br />
<b>Fanghui Liu</b>, Johan A.K. Suykens, Volkan Cevher. <br />
in the 36th Conference on Neural Information Processing Systems (<b>NeurIPS</b>), 2022. <br />
Presented at <a href="https://topml.rice.edu/" target=&ldquo;blank&rdquo;>Workshop on the Theory of Overparameterized Machine Learning (TOPML) 2022</a>.</p>
</li>
</ul>
<ul>
<li><p><i>Understanding deep neural function approximation in reinforcement learning via \(\epsilon\)-greedy exploration</i>. 
[<a href="https://arxiv.org/abs/2209.07376" target=&ldquo;blank&rdquo;>arXiv</a>]. <br />
<b>Fanghui Liu</b>, Luca Viano, Volkan Cevher. <br />
in the 36th Conference on Neural Information Processing Systems (<b>NeurIPS</b>), 2022. <br /></p>
</li>
</ul>
<ul>
<li><p><i>Robustness in deep learning: The good (width), the bad (depth), and the ugly (initialization)</i>. <br />
Zhenyu Zhu, <b>Fanghui Liu</b>,  Grigorios Chrysos, Volkan Cevher. 
[<a href="https://arxiv.org/abs/2209.07263" target=&ldquo;blank&rdquo;>arXiv</a>]. <br />
in the 36th Conference on Neural Information Processing Systems (<b>NeurIPS</b>), 2022. <br /></p>
</li>
</ul>
<ul>
<li><p><i>Generalization properties of NAS under activation and skip connection search</i>. <br />
Zhenyu Zhu, <b>Fanghui Liu</b>, Grigorios Chrysos, Volkan Cevher.
[<a href="https://arxiv.org/abs/2209.07238" target=&ldquo;blank&rdquo;>arXiv</a>]. <br />
in the 36th Conference on Neural Information Processing Systems (<b>NeurIPS</b>), 2022. <br /></p>
</li>
</ul>
<ul>
<li><p><i>Extrapolation and spectral bias of neural nets with Hadamard product: a polynomial net study</i>. <br />
Yongtao Wu, Zhenyu Zhu, <b>Fanghui Liu</b>, Grigorios Chrysos, Volkan Cevher. <br />
in the 36th Conference on Neural Information Processing Systems (<b>NeurIPS</b>), 2022. <br /></p>
</li>
</ul>
<ul>
<li><p><i>Sound and complete verification of polynomial networks</i>. <br />
Elias Abad Rocamora, Mehmet Fatih Sahin, <b>Fanghui Liu</b>, Grigorios Chrysos, Volkan Cevher. 
[<a href="https://arxiv.org/abs/2209.07235" target=&ldquo;blank&rdquo;>arXiv</a>]. <br />
in the 36th Conference on Neural Information Processing Systems (<b>NeurIPS</b>), 2022. <br /></p>
</li>
</ul>
<ul>
<li><p><i>Random features for kernel approximation: A Survey on algorithms, theory, and beyond</i>.
[<a href="https://arxiv.org/abs/2004.11154" target=&ldquo;blank&rdquo;>arXiv</a>], [<a href="files/RFFsurvey_demo.zip" target=&ldquo;blank&rdquo;>code</a>]. <br />
<b>Fanghui Liu</b>, Xiaolin Huang, Yudong Chen, and Johan A.K. Suykens. <br />
IEEE Transactions on Pattern Analysis and Machine Intelligence (<b>TPAMI</b>), 2021.</p>
</li>
</ul>
<ul>
<li><p><i>Generalization properties of hyper-RKHS and its applications</i>.
[<a href="https://jmlr.org/papers/v22/19-482.html" target=&ldquo;blank&rdquo;>link</a>], [<a href="files/demo-hyperRKHS.zip" target=&ldquo;blank&rdquo;>code</a>]. <br />
<b>Fanghui Liu</b>*, Lei Shi*, Xiaolin Huang, Jie Yang, and Johan A.K. Suykens. <br />
Journal of Machine Learning Research (<b>JMLR</b>), 2021.</p>
</li>
</ul>
<ul>
<li><p><i>Towards a unified quadrature framework for large scale kernel methods</i>.
[<a href="https://arxiv.org/abs/2011.01668" target=&ldquo;blank&rdquo;>arXiv</a>], [<a href="files/Quadrature_demo.zip" target=&ldquo;blank&rdquo;>code</a>]. <br />
<b>Fanghui Liu</b>, Xiaolin Huang, Yudong Chen, and Johan A.K. Suykens.<br />
IEEE Transactions on Pattern Analysis and Machine Intelligence (<b>TPAMI</b>), 2021.</p>
</li>
</ul>
<ul>
<li><p><i>Kernel regression in high dimensions: Refined analysis beyond double descent</i>.
[<a href="http://proceedings.mlr.press/v130/liu21b.html" target=&ldquo;blank&rdquo;>link</a>], [<a href="files/demo_KRRhigh.m" target=&ldquo;blank&rdquo;>code</a>]. <br />
<b>Fanghui Liu</b>, Zhenyu Liao, and Johan A.K. Suykens.<br /> 
in the 24th International Conference on Artificial Intelligence and Statistics (<b>AISTATS</b>), 2021.</p>
</li>
</ul>
<ul>
<li><p><i>Fast learning in reproducing kernel Krein spaces via signed measures</i>.
[<a href="http://proceedings.mlr.press/v130/liu21a.html" target=&ldquo;blank&rdquo;>link</a>], [<a href="files/RFF_RKKS_poster.pdf" target=&ldquo;blank&rdquo;>poster</a>],
[<a href="files/code-RFF_RKKS.zip" target=&ldquo;blank&rdquo;>code</a>]. <br />
<b>Fanghui Liu</b>, Xiaolin Huang, Yingyi Chen, and Johan A.K. Suykens. <br />
in the 24th International Conference on Artificial Intelligence and Statistics (<b>AISTATS</b>), 2021.</p>
</li>
</ul>
<ul>
<li><p><i>Analysis of least squares regularized regression in reproducing kernel Krein spaces</i>.
[<a href="https://arxiv.org/abs/2006.01073" target=&ldquo;blank&rdquo;>arXiv</a>]. <br />
<b>Fanghui Liu</b>*, Lei Shi*, Xiaolin Huang, Jie Yang, and Johan A.K. Suykens. <br />
<b>Machine Learning</b>, 2021.</p>
</li>
</ul>
<ul>
<li><p><i>Learning data-adaptive nonparametric kernels</i>.
[<a href="https://jmlr.org/papers/v21/19-900.html" target=&ldquo;blank&rdquo;>link</a>] [<a href="files/NesterovAcc.m" target=&ldquo;blank&rdquo;>code</a>]. <br />
<b>Fanghui Liu</b>, Xiaolin Huang, Chen Gong, Jie Yang, and Li Li. <br />
Journal of Machine Learning Research (<b>JMLR</b>), 2020.</p>
</li>
</ul>
<ul>
<li><p><i>Random Fourier features via fast surrogate leverage weighted sampling</i>.
[<a href="https://arxiv.org/abs/1911.09158" target=&ldquo;blank&rdquo;>arXiv</a>], [<a href="files/AAAI20_code.zip" target=&ldquo;blank&rdquo;>code</a>].<br /> 
<b>Fanghui Liu</b>, Xiaolin Huang, Yudong Chen, Jie Yang, and Johan A.K. Suykens. <br />
in the Thirty-Fourth AAAI Conference on Artificial Intelligence (<b>AAAI</b>), 2020.</p>
</li>
</ul>
<ul>
<li><p><i>A double-variational Bayesian framework in random Fourier features 
for indefinite kernels</i>.
[<a href="https://lirias.kuleuven.be/retrieve/554716" target=&ldquo;blank&rdquo;>link</a>], [<a href="files/RFF-DIGMM_code.zip" target=&ldquo;blank&rdquo;>code</a>].<br />
<b>Fanghui Liu</b>, Xiaolin Huang, Lei Shi, Jie Yang, and Johan A.K. Suykens.<br /> 
IEEE Transactions on Neural Networks and Learning Systems (<b>TNNLS</b>), 2019.</p>
</li>
</ul>
<ul>
<li><p><i>Indefinite kernel logistic regression with Concave-inexact-convex procedure</i>.
[<a href="https://arxiv.org/abs/1707.01826" target=&ldquo;blank&rdquo;>arXiv</a>], [<a href="IKLR_code.zip" target=&ldquo;blank&rdquo;>code</a>]. <br />
<b>Fanghui Liu</b>, Xiaolin Huang, Chen Gong, Jie Yang, and Johan A.K. Suykens. <br />
IEEE Transactions on Neural Networks and Learning Systems (<b>TNNLS</b>), 2018.</p>
</li>
</ul>
</div> <!-- <div id="layout-content-container"> -->
</div> <!--- <div id="layout"> --->
</div> <!--- <div id="main-container"> --->
<script>
function openNav() {
    if (window.innerWidth <= 1200) {
        document.getElementById("layout-menu").style.width = "280px";
        document.getElementById("layout-content-container").style.marginLeft = "280.8px";
        document.getElementById("layout-content-container").style.position = "fixed";
    }
}
function closeNav() {
    if (window.innerWidth <= 1200) {
        document.getElementById("layout-menu").style.width = "0";
        document.getElementById("layout-content-container").style.position = "static";
        document.getElementById("layout-content-container").style.marginLeft = "0px";
        setInterval(
            function(){ location.reload() },
            500
        );
    }
}
</script>
</body>
</html>

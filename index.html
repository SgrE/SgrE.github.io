<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="icon" href="images/icon.png">
<link rel="stylesheet" href="main.css" type="text/css" />
<link rel="stylesheet" href="font-awesome/css/font-awesome.min.css">
<!--- <title>Welcome to Fanghui Liu (刘方辉)'s Homepage!</title> --->
<title>Fanghui Liu</title>
<!-- MathJax -->
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML' async>
</script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
	  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
<!-- End MathJax -->
</head>
<body>
<div id="main-container">
<div id="header-container">
<div id="header">
<div id="header-icon-text-container">
<div id="header-icon-container" >
<a href="index.html"><img src="images/profile2.png" alt="" style="width: 100%; height: 100%; position: center; padding:0px; margin: 0px;"></a>
</div>
<div id="header-text-container">
<a href="index.html">Fanghui Liu</a>
</div>
</div>
<div id="main">
<button class="openbtn" onclick="openNav()">☰</button>
</div>
</div>
</div>
<div id="layout">
<div id="layout-menu-container">
<div id="layout-menu">
<div class="menu-item"><a href="javascript:void(0)" class="closebtn" onclick="closeNav()">×</a></div>
<div class="menu-item"><a href="index.html" class="current">About</a></div>
<div class="menu-category">Research</div>
<div class="menu-item"><a href="publications.html">Publications</a></div>
<div class="menu-item"><a href="talks.html">Talks</a></div>
<div class="menu-item"><a href="awards.html">Awards</a></div>
<div class="menu-category">Teaching</div>
<div class="menu-item"><a href="teaching.html">Courses</a></div>
<div class="menu-item"><a href="tutorials.html">Tutorials</a></div>
<div class="menu-category">Supervision</div>
<div class="menu-item"><a href="students.html">Students</a></div>
<div class="menu-item"><a href="positions.html">Open&nbsp;Positions</a></div>
<div class="menu-category">Service</div>
<div class="menu-item"><a href="services.html">Academic&nbsp;Service</a></div>
<div class="menu-item"><a href="workshop.html">NeurIPS&rsquo;24&nbsp;FITML&nbsp;Workshop</a></div>
</div> <!-- <div id="layout-menu"> -->
</div> <!-- <div id="layout-menu-container"> -->
<div id="layout-content-container">
<div id="layout-content">
<div id="toptitle">
<h1>Welcome to Fanghui Liu (刘方辉)'s Homepage!</h1>
</div>
<div id="text-img-container"><div id="img-container">
<img src="images/me.jpg" alt="alt text" width="200px" height="200px" /></div>
<div id="text-container"><h1>About me <br /></h1>
<p>I'm an assistant professor at <a href="https://warwick.ac.uk/fac/sci/dcs/" target=&ldquo;blank&rdquo;>Department of Computer Science</a>, a faculty member of <a href="https://warwick.ac.uk/fac/cross_fac/dimap/" target=&ldquo;blank&rdquo;>Centre for Discrete Mathematics and its Applications (DIMAP)</a>, an affiliated member of <a href="https://warwick.ac.uk/fac/sci/dcs/research/focs/people/" target=&ldquo;blank&rdquo;>the Division of Theory and Foundations (FoCS)</a>, at the University of Warwick, UK, and a TUM Global Visiting Professor.</p>
<p>Email: <b>x</b>@<b>y</b> with <b>x</b>=fanghui.liu and <b>y</b>=warwick.ac.uk <br /></p>
<p>[<a href="https://scholar.google.com/citations?user=AKxBgssAAAAJ" target=&ldquo;blank&rdquo;>Google Scholar</a>] 
[<a href="https://openreview.net/profile?id=~Fanghui_Liu1" target=&ldquo;blank&rdquo;>OpenReview</a>]
[<a href="files/bio.text" target=&ldquo;blank&rdquo;>speaker bio</a>]
<br /></p>
</div></div>
<p>The website was updated at Nov. 3rd, 2025.</p>
<h2>Research Interests </h2>
<p>I'm generally interested in <b>foundations of modern machine learning</b> from the lens of <b>learning efficiency</b>, both theoretically and empirically. My research is always contributing to how to <b>handle nonlinearity at a theoretical level</b> and how to precisely and efficiently <b>approximate nonlinearity at a practical level</b> under theoretical guidelines, which is a longstanding question over science, technology and engineering.</p>
<div id="text-img-container"><div id="img-container">
<img src="images/RS_mini.jpg" alt="alt text" width="850px" height="220px" /></div>
<div id="text-container"></div></div>
<p>My research (the past, ongoing and future) focuses on the following directions:</p>
<ul>
<li><p>machine learning theory: what is the largest function space that can be learned by neural networks, both statistically and computationally efficiently (computational-statistical gaps)?</p>
</li>
<li><p>post-training in LLMs:  expand the frontiers of empirical and theoretical knowledge on when and where to fine-tune<i>inference, and how much we can fine-tune</i>inference, precisely, efficiently, and robustly</p>
</li>
</ul>
<p>My research is supported by grants from Royal Society (UK), Alan Turing Institute (UK), and DAAD (Germany).</p>
<p>We're organising <a href="https://ijcvsi25pt.github.io/" target=&ldquo;blank&rdquo;><b><font color="DarkMagenta"> IJCV Special Issue on Post-Training in Large Language Models for Computer Vision</font></b></a>!</p>
<h2>Jobs</h2>
<p><b><font color="red">The position for 2026 Fall is fulfilled.</font></b> See <a href="https://www.lfhsgre.org/positions.html" target=&ldquo;blank&rdquo;>Open positions</a> for details.</p>
<p>As our department requires a research proposal as part of the PhD application, I strongly encourage interested candidates to contact me <b>in advance of the application deadline</b> (check <a href="https://warwick.ac.uk/fac/sci/dcs/research/cscdt/fundingadvice" target=&ldquo;blank&rdquo;>website</a> for details). If you are a strong fit based on my evaluation, I will spend some time to support you in preparing a competitive proposal and application.</p>
<p>Due to a large number of requests, I, unfortunately, may not be able to reply to all the emails regarding PhD applications. However, I'll look at applicants that have sent me emails and contact you soon if your enquires are indeed inline with my research.</p>
<h2>News</h2>
<ul>
<li><p>[2025-10] I was selected to <a href="https://www.international.tum.de/global/visitingprofessors/" target=&ldquo;blank&rdquo;>TUM Global Visiting Professor Program</a>.</p>
</li>
</ul>
<ul>
<li><p>[2025-10] One paper on a new pipeline for step-level CoT was released on <a href="https://arxiv.org/abs/2510.19842" target=&ldquo;blank&rdquo;>arXiv</a>.</p>
</li>
</ul>
<ul>
<li><p>[2025-09] One paper on precise characterization of generalization curve was accepted by NeurIPS&rsquo;25. Congratulations to Yichen! <b><font color="DarkMagenta">See you at San Diego</font></b></p>
</li>
</ul>
<ul>
<li><p>[2025-09] I obtained the Advanced HE fellowship certificate for UK high education.</p>
</li>
</ul>
<ul>
<li><p>[2025-08] I will be the area chair of ICLR&rsquo;26 and AISTATS&rsquo;26.</p>
</li>
</ul>
<ul>
<li><p>[2025-08] I attended the <a href="https://delta-workshop.github.io/deep-learning-theory-2025" target=&ldquo;blank&rdquo;>Deep Learning Theory Workshop 2025</a> and gave a talk about LoRA-One.</p>
</li>
</ul>
<ul>
<li><p>[2025-05] One paper on fine-tuning (LoRA-One) was accepted by ICML&rsquo;25 as Oral. Congratulations to Yuanhe!</p>
</li>
</ul>
<ul>
<li><p>[2025-03] I will be the area chair of NeurIPS&rsquo;25.</p>
</li>
</ul>
<ul>
<li><p>[2025-02] Attended <a href="https://ita.ucsd.edu/workshop/" target=&ldquo;blank&rdquo;>2025 ITA Workshop</a> and visited UCLA.</p>
</li>
</ul>
<ul>
<li><p>[2025-01] One paper was accepted by ICLR&rsquo;25. It's about how gradient descent balances features after weak recovery.</p>
</li>
</ul>
<ul>
<li><p>[2024-12] We organised one workshop <a href="https://sites.google.com/view/neurips2024-ftw/home" target=&ldquo;blank&rdquo;><b><font color="red">Fine-Tuning in Modern Machine Learning: Principles and Scalability</font></b></a> at NeurIPS 2024!</p>
</li>
</ul>
<ul>
<li><p>[2024-09] I will attend <a href="https://www.crm.cat/mathematical-aspects-of-learning-theory/" target=&ldquo;blank&rdquo;>Mathematical Aspects of Learning Theory Workshop - 20 years later</a>.</p>
</li>
</ul>
<ul>
<li><p>[2025-08] I will be the area chair of ICLR&rsquo;25 and AISTATS&rsquo;25.</p>
</li>
</ul>
<ul>
<li><p>[2024-05] Two papers were accepted by ICML 2024: one is about high dimensional kernel methods under distribution shift; one is about adversarial attack on foundation models.</p>
</li>
</ul>
<ul>
<li><p>[2024-04] One paper was accepted by JMLR on the separation between kernel methods and neural networks from the perspective of function space.</p>
</li>
</ul>
<ul>
<li><p>[2023-04] We will give a tutorial entitled <b>Scaling and Reliability Foundations in Machine Learning</b> at 2024 IEEE International Symposium on Information Theory (ISIT) in Athens, Greece at July.</p>
</li>
</ul>
<ul>
<li><p>[2024-04] Awarded the <a href="https://www.daad.de/en/the-daad/postdocnet/details-and-application/" target=&ldquo;blank&rdquo;>DAAD AInet Fellowship</a>, which is awarded to outstanding early career researchers. Topic: Safety and Security in AI.</p>
</li>
</ul>
<ul>
<li><p>[2024-03] The adversarially trained NAS benchmark (<b>NAS-RobBench-201</b>) in <a href="https://openreview.net/pdf?id=cdUpf6t6LZ" target=&ldquo;blank&rdquo;>our ICLR24 paper</a> was released! See [<a href="https://tt2408.github.io/nasrobbench201hp/" target=&ldquo;blank&rdquo;>project website</a>] for details.</p>
</li>
</ul>
<ul>
<li><p>[2024-01] Three papers were accepted by ICLR 2024: generalization of ResNets; robust NAS from benchmark to theory; local-linearity for catastrophic overfitting. <b><font color="DarkMagenta">I will be at Vienna. Feel free to chat.</font></b></p>
</li>
</ul>
<ul>
<li><p>[2023-12] Selected to give a talk at <a href="https://aaai.org/aaai-conference/aaai-24-new-faculty-highlights/" target=&ldquo;blank&rdquo;>AAAI 2024 New Faculty Highlights</a>.</p>
</li>
</ul>
<ul>
<li><p>[2023-09] Two papers were accepted by NeurIPS 2023: one is about global convergence of Transformers; the other one is how over-parameterization affects differential privacy. <b><font color="DarkMagenta">I will be at New Orleans (again and again). Feel free to chat.</font></b></p>
</li>
</ul>
<ul>
<li><p>[2023-06] Here is the slides of our <a href="files/CVPR_tutorial.pdf" target=&ldquo;blank&rdquo;>CVPR 2023 tutorial</a>.</p>
</li>
</ul>
<ul>
<li><p>[2023-06] Here is the slides of our <a href="files/ICASSP23_tutorial.pdf" target=&ldquo;blank&rdquo;>ICASSP 2023 tutorial</a>.</p>
</li>
</ul>
<ul>
<li><p>[2023-04] Two papers were accepted by ICML 2023: one is about function approximation in online RL; the other one is related to benign overfitting. <b><font color="DarkMagenta">I will be at Hawaii! Feel free to chat.</font></b></p>
</li>
</ul>
<ul>
<li><p>[2023-04] Selected as a <a href="https://iclr.cc/Conferences/2023/Reviewers" target=&ldquo;blank&rdquo;>Notable Reviewer</a> for ICLR 2023.</p>
</li>
</ul>
<ul>
<li><p>[2023-02] We will give a tutorial entitled <b>Deep learning theory for computer vision</b> at IEEE CVPR 2023 in Vancouver, Canada.</p>
</li>
</ul>
<ul>
<li><p>[2023-02] I will attend <a href="https://cemse.kaust.edu.sa/ai/aii-symp-2023" target=&ldquo;blank&rdquo;>the Rising Stars in AI Symposium 2023</a> at KAUST in Saudi Arabia (Feb. 19-21).</p>
</li>
</ul>
<ul>
<li><p>[2022-12] We will give a tutorial entitled <b>Neural networks: the good, the bad, the ugly</b> at IEEE ICASSP 2023 in the Greek island of Rhodes.</p>
</li>
</ul>
<ul>
<li><p>[2022-09] Six papers were accepted by NeurIPS 2022.</p>
</li>
</ul>
<ul>
<li><p>[2021-10] One paper on double descent of RFF with SGD was posted on 
<a href="https://arxiv.org/abs/2110.06910" target=&ldquo;blank&rdquo;>arXiv</a>.</p>
</li>
</ul>
<ul>
<li><p>[2021-10] One paper was accepted by IEEE Transactions on Pattern Analysis and Machine Intelligence.</p>
</li>
</ul>
<ul>
<li><p>[2021-07] One paper was accepted by IEEE Transactions on Pattern Analysis and Machine Intelligence.</p>
</li>
</ul>
<ul>
<li><p>[2021-06] One paper was accepted by Journal of Machine Learning Research.</p>
</li>
</ul>
<ul>
<li><p>[2021-02] One paper was accepted by Machine Learning.</p>
</li>
</ul>
<ul>
<li><p>[2021-01] Two papers were accepted by AISTATS 2021.</p>
</li>
</ul>
<ul>
<li><p>[2020-10] One paper was accepted by Journal of Machine Learning Research.</p>
</li>
</ul>
<h2>Visitors</h2>
<script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=080808&w=260&t=tt&d=CSj_lwkJPnjLuoGvBe6VD-xJaql8MX8sFoN-GPUfX38&co=ffffff&cmo=3acc3a&cmn=ff5353&ct=808080'></script>
</div> <!-- <div id="layout-content"> -->
<div id="footer-container">
<div id="footer">
<div id="footer-text">
Powered by <a href="https://github.com/szl2/jemdoc-new-design" target="blank">jemdoc + new design</a>.
</div> <!-- <div id="footer-text"> -->
</div> <!-- <div id="footer"> -->
</div> <!-- <div id="footer-container"> -->
</div> <!-- <div id="layout-content-container"> -->
</div> <!--- <div id="layout"> --->
</div> <!--- <div id="main-container"> --->
<script>
function openNav() {
    if (window.innerWidth <= 1200) {
        document.getElementById("layout-menu").style.width = "280px";
        document.getElementById("layout-content-container").style.marginLeft = "280.8px";
        document.getElementById("layout-content-container").style.position = "fixed";
    }
}
function closeNav() {
    if (window.innerWidth <= 1200) {
        document.getElementById("layout-menu").style.width = "0";
        document.getElementById("layout-content-container").style.position = "static";
        document.getElementById("layout-content-container").style.marginLeft = "0px";
        setInterval(
            function(){ location.reload() },
            500
        );
    }
}
</script>
</body>
</html>
